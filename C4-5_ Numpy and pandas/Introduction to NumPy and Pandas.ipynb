{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `numpy` and `pandas` to hold and manipulate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "Two of the most useful libraries for working with scientific data are `numpy` and `pandas`. `Numpy` lets you set up n-dimensional arrays of data (ndarrays), slice and manipulate that data, and perform various operations on those arrays. `Pandas` builds on that functionality by focusing on rigidly defined lists (Series) and 2D tables (DataFrames aka \"panel data\", whence comes `pandas`). `Pandas` also makes data import and manipulation simpler and more intuitive than `numpy`. However in exchange for being simpler to write and read, `pandas` can be slower. \n",
    "\n",
    "In addition to `numpy` and `pandas`, we will touch on `scipy`, which is also built on top of `numpy`. `Scipy` lets you input `numpy` arrays into a wide range of statistical and modeling methods.\n",
    "\n",
    "The lines between these libraries are blurry, and often you can do the same functions using either package with slightly different syntax. \n",
    "\n",
    "Most python plotting packages use `numpy` ndarrays or `pandas` DataFrames as input. We will use some plotting methods below to visualize what we are doing with our DataFrame without actually covering how to use those functions, but don't panic! We will focus on plotting later in the course. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and initial data inspection \n",
    "\n",
    "First we need to import the libraries we want to use. This is the same process you used for the last homework to add new functions to your python \"environment\". These packages add hundreds of new functions\n",
    "\n",
    "When you import these libraries you can also give them an alias, which is easier to remember and type. The ones used below are common for these packages. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differences between lists and NumPy Arrays\n",
    "* An array's size is immutable.  You cannot append, insert or remove elements, like you can with a list.\n",
    "* All of an array's elements must be of the same [data type](https://docs.scipy.org/doc/numpy-1.14.0/user/basics.types.html).\n",
    "* A NumPy array behaves in a Pythonic fashion.  You can `len(my_array)` just like you would assume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpas_as_list = [4.0, 3.286, 3.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can have elements appended to it\n",
    "gpas_as_list.append(4.0)\n",
    "# Can have multiple datatypes in it.\n",
    "gpas_as_list.insert(1, \"Whatevs\")\n",
    "# Can have items removed\n",
    "gpas_as_list.pop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpas_as_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpas = np.array(gpas_as_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpas.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpas.itemsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpas.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gpas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpas.nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multidimensional Arrays\n",
    "* The data structure is actually called `ndarray`, representing any **n**umber of **d**imensions\n",
    "* Arrays can have multiple dimensions, you declare them on creation\n",
    "* Dimensions help define what each element in the array represents.  A two dimensional array is just an array of arrays\n",
    "* **Rank** defines how many dimensions an array contains \n",
    "* **Shape** defines the length of each of the array's dimensions\n",
    "* Each dimension is also referred to as an **axis**, and they are zero-indexed. Multiples are called **axes**.\n",
    "* A 2d array is AKA **matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_gpas = np.array([\n",
    "    [4.0, 3.286, 3.5, 4.0],\n",
    "    [3.2, 3.8, 4.0, 4.0],\n",
    "    [3.96, 3.92, 4.0, 4.0]\n",
    "], np.float16)\n",
    "students_gpas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_gpas.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_gpas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_gpas.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(students_gpas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_gpas.itemsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_gpas.itemsize * students_gpas.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.info(students_gpas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_gpas[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_gpas[2][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_gpas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Routines\n",
    "* Common [mathematical](https://docs.scipy.org/doc/numpy-1.14.0/reference/routines.math.html) [routines](https://docs.scipy.org/doc/numpy-1.14.0/reference/routines.html) are exposed so the formula can be abstracted away.\n",
    "    * [`mean`](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.mean.html#numpy.mean) is a [statistics](https://docs.scipy.org/doc/numpy-1.14.0/reference/routines.statistics.html) routine used to calculate the average.\n",
    "* Reduction functions take a dimension and collapse it into a single value.\n",
    "    * These functions define an axis parameter, and you should remember that the function works across the dimension.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_gpas.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_gpas.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(students_gpas.T)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About data types\n",
    "* By choosing the proper [data type](https://docs.scipy.org/doc/numpy-1.14.0/user/basics.types.html) you can greatly reduce the size required to store objects\n",
    "* Data types are maintained by wrapping values in a [scalar representation](https://docs.scipy.org/doc/numpy-1.14.0/reference/arrays.scalars.html)\n",
    "* `np.zeros` is a handy way to create an empty array filled with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_minutes = np.zeros(100, np.uint16)\n",
    "study_minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "60 * 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_minutes[0] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_day_minutes = study_minutes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_day_minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(first_day_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add 60 minutes to the second day in the study_minutes array\n",
    "study_minutes[1] = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_minutes[2:6] = [80, 60, 30, 90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation \n",
    "* You can create a random but bound grouping of values using the `np.random` package.  \n",
    "  * `RandomState` let's you seed your randomness in a way that is repeatable.\n",
    "* You can append a row in a couple of ways\n",
    "   * You can use the `np.append` method.  Make sure the new row is the same shape.\n",
    "   * You can create/reassign a new array by including the existing array as part of the iterable in creation.\n",
    "\n",
    "\n",
    "## Indexing\n",
    "* You can use an indexing shortcut by separating dimensions with a comma.  \n",
    "* You can index using a `list` or `np.array`.  Values will be pulled out at that specific index.  This is known as fancy indexing.\n",
    "  * Resulting array shape matches the index array layout.  Be careful to distinguish between the tuple shortcut and fancy indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_minutes = np.array([\n",
    "    study_minutes,\n",
    "    np.zeros(100, np.uint16)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_minutes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set round 2 day 1 to 60\n",
    "study_minutes[1][0] = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_minutes[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = np.random.RandomState(42)\n",
    "fake_log = rand.randint(30, 180, size=100, dtype=np.uint16)\n",
    "fake_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[fake_log[3], fake_log[8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_log[[3, 8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.array([\n",
    "    [3, 8],\n",
    "    [0, 1]\n",
    "])\n",
    "fake_log[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_minutes = np.append(study_minutes, [fake_log], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_minutes[1, 1] = 360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean Array Indexing\n",
    "* You can create a boolean array by using comparison operators on an array.\n",
    "  * You can use boolean arrays for fancy indexing.\n",
    "  * Boolean arrays can be compared by using bitwise operators (`&`, `|`)\n",
    "      * Do not use the `and` keyword.\n",
    "      * Remember to mind the order of operations when combining\n",
    "* Even though boolean indexing returns a new array, you can update an existing array using a boolean index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_log[fake_log < 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for value in fake_log:\n",
    "    if value < 60:\n",
    "        results.append(value)\n",
    "np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_minutes[study_minutes < 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([False, True, True]) & np.array([True, False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_minutes[(study_minutes < 60) & (study_minutes > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_minutes[study_minutes < 60] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_minutes[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Functions - Reduce / Accumulate\n",
    "* Universal Functions expose a function to [`reduce`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ufunc.reduce.html) an array to a single value.\n",
    "* There is also a function named [`accumulate`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ufunc.accumulate.html) which will show the reduction and it's accumulation as it happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.add.reduce(study_minutes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.add.accumulate(study_minutes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(study_minutes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(study_minutes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in a one dimensional array of all the minutes that are \n",
    "#  greater than zero\n",
    "plt.hist(study_minutes[study_minutes > 0])\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing\n",
    "* Works a lot like normal list slicing.\n",
    "* You can use commas to separate each dimension slice.\n",
    "* Always returns a data view **not a copy**\n",
    "* You can access the base object using the `ndarray.base` property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit = [\"apple\", \"banana\", \"cherry\", \"durian\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copied = fruit[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copied[3] = 'cheese'\n",
    "# Slicing a list returns a copy\n",
    "fruit, copied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "practice = np.arange(42)\n",
    "practice.shape = (7, 6)\n",
    "practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "practice[2:5, 3::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any slicing of ndarray returns a view and not a copy!\n",
    "not_copied = practice[:]\n",
    "not_copied[0, 0] = 90210\n",
    "practice, not_copied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "practice.base is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_copied.base is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_copied.base is practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "practice.flags['OWNDATA'], not_copied.flags['OWNDATA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array Manipulation\n",
    "* The documentation on [Array Manipulation](https://docs.scipy.org/doc/numpy/reference/routines.array-manipulation.html) is a good one to keep bookmarked.\n",
    "* `ndarray.reshape` creates a view with a new shape\n",
    "  * You can use `-1` as a value to infer the missing dimension\n",
    "* `ndarray.ravel` returns a single dimensional view of the array.\n",
    "* `ndarray.flatten` can be used to make a single dimensional copy.\n",
    "* `np.lookfor` is great for searching docstrings from within a notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "practice_view = practice.reshape(3, 14)\n",
    "practice, practice_view, practice_view.base is practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "practice.reshape(-1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "practice.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra\n",
    "* There is a module for linear algebra, [linalg](https://docs.scipy.org/doc/numpy/reference/routines.linalg.html)\n",
    "* You can solve for a system of equations using the [solve function](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.solve.html#numpy.linalg.solve)\n",
    "    * You can create a square 2 dimensional matrix and a constant row vector and solve for each variable column\n",
    "    * You can double check the answer using the inner product or [dot](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html#numpy.dot).\n",
    "* You can use the `@` to produce the dot product of two arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = np.array([\n",
    "    [2, 0, 0, 0],\n",
    "    [4, 1, 2, 2],\n",
    "    [0, 1, 0, 1],\n",
    "    [6, 0, 1, 2]\n",
    "])\n",
    "totals = np.array([3, 20.50, 10, 14.25])\n",
    "prices = np.linalg.solve(orders, totals)\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A â€¢ B\n",
    "orders @ prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.dot(prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Functions\n",
    "* [ufuncs](https://docs.scipy.org/doc/numpy/reference/ufuncs.html) are commonly needed vectorized functions\n",
    "  * Vectorized functions allow you to operate element by element without using a loop\n",
    "* The standard math and comparison operations have all been overloaded so that they can make use of vectorization\n",
    "* Values can be [broadcasted](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html), or stretched to be applied to the ufuncs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = np.split(np.arange(1, 11), 2)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b - a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a + np.repeat(2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> x1 = np.arange(9.0).reshape((3, 3))\n",
    ">>> x2 = np.arange(3.0)\n",
    "x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> np.add(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.add(x1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Pandas` for tidy data management\n",
    "\n",
    "Prior to `pandas` python was a useful language for pulling together data and preparing it for data analysis, but `R` (another programming language) was more popular for analysis and modeling. One advantage of `R` is the way it handles arrays of data using a type of object called a DataFrame that had a lot of useful methods. Think of a DataFrame as an Excel spreadsheet in computer memory. \n",
    "\n",
    "`Pandas` brings DataFrames to python. \n",
    "\n",
    "Let's import some data to work with. `Pandas` provides simple tools for importing from Excel, csv, or any other common data format. Here we are going to use the `read_csv` command to pull in a table of RNAseq data from a [melanoma study from 2017](https://www.nature.com/articles/s41467-017-02353-y) published in Nature Communications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use these packages by typing in the alias followed by a '.' and a method name. We'll start by importing a table of expression data using `read_csv` and a table of metadata using `read_excel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is tab separated and the first column has the gene names\n",
    "# Remember that most things in python are zero-indexed, so the first\n",
    "# column is index 0\n",
    "df = pd.read_csv('data\\GSE88741-expression.txt', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pandas` introduces two new ways of collecting variables:\n",
    "\n",
    " - Series: A named list of values, all of the same type\n",
    " - DataFrame: Basically an Excel spreadsheet in computer memory. Each column is a different Series of data, and each row is a separate observation or sample.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at the imported data\n",
    "# The number of rows and columns in a DataFrame can be found at df.shape\n",
    "print (df.shape)\n",
    "\n",
    "# Let's take a look at the top of `df` using df.head()\n",
    "# Input a number between the parentheses to indicate how many lines you want to see- 5 is default\n",
    "print (df.head())\n",
    "\n",
    "# Note: Why don't we need parentheses after `df.shape`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe() shows a quick statistics summary of your data\n",
    "# round() limits the number of significant digits\n",
    "# You can chain together functions like we do here with round\n",
    "df.describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a large dataset, so lets take a small random sample to work with\n",
    "# the sample() method randomly selects a number of rows or columns from a larger DataFrame\n",
    "# We are setting the random_state here so that we all use the same random genes\n",
    "df_sample = df.sample(100, axis = 0, random_state = 333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Dimensions of DataFrame:\",df_sample.shape)\n",
    "print (df_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring in the metadata from an excel spreadsheet\n",
    "meta = pd.read_excel(\"data/GSE88741-metadata.xlsx\", index_col=1)\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's extract the Sample Titles and use them to replace the ugly GSM names\n",
    "columns = meta.index\n",
    "print (type(columns))\n",
    "df_sample.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice how we set the column names above\n",
    "# We can use that command to show us index and column names as well\n",
    "print(df_sample.index)\n",
    "print(df_sample.columns)\n",
    "print(df_sample.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing and sorting\n",
    "Getting subsets of data out of `pandas` DataFrames is done primarily in one of two ways.\n",
    "If you want to search for row and column names, you use .loc()\n",
    "You can instead use the indexes to select the data you want using .iloc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's sort by the index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.UACC_62_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can send our DataFrame into a numpy array\n",
    "# ndarrays can only be one type of data, so if we added any metadata\n",
    "# this would convert to whatever data type works for all data types present\n",
    "\n",
    "nda = df.to_numpy()\n",
    "type(nda)\n",
    "#nda.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
